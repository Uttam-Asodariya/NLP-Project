{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment for BERT Word embedding notebook\n",
    "import torch\n",
    "from transformers import (AutoModelWithLMHead, \n",
    "                          AutoTokenizer, \n",
    "                          BertConfig,BertTokenizer,BertModel)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary-multilingual)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'my', 'name', 'is', 'ut', '##tam', 'as', '##oda', '##ri', '##ya', 'and', 'i', 'am', 'a', 'fa', '##u', 'student', '.', '[SEP]']\n",
      "[101, 2026, 2171, 2003, 21183, 15464, 2004, 13390, 3089, 3148, 1998, 1045, 2572, 1037, 6904, 2226, 3076, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "# Bert need special kind of input format, with special tokens to mark beginning([CLS]) and seperation/end([SEP]).\n",
    "text = \"My Name is Uttam Asodariya and I am a FAU student.\" #simple example\n",
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "'''Now, we need to tokenize our senteces(text) according to BERT's vocabulary. For each tokenized sentence, \n",
    "   BERT requires input ids. EX: bird-->2293 \n",
    "   '''\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(marked_text) # Tokenize our sentence with the BERT tokenizer.\n",
    "\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text) # Map the token strings to their vocabulary indeces.\n",
    "\n",
    "# Print out the tokens.\n",
    "print(tokenized_text)\n",
    "print (indexed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the text through BERT, get the output and collect all of the hidden states produced from all 12 layers.\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    last_hidden_state = outputs[0]\n",
    "    word_embed = last_hidden_state\n",
    "    hidden_states = outputs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 13   (Input embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 19\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "'''Here, Our main goal is word embedding so we only limit out vision untill encoding part,\n",
    "   which is hidden_state in BERT model. Full set of hidden states of model, stored in the object hidden_states.\n",
    "   It has following for dimension: 1)The Layer number\n",
    "                                   2)The batch number (num of sentences)\n",
    "                                   3)The word/token number (maximum length of sentences)\n",
    "                                   4)The hidden unit/feature number (768 features)\n",
    "   '''\n",
    "\n",
    "   \n",
    "print (\"Number of layers:\", len(hidden_states), \"  (Input embeddings + 12 BERT layers)\")\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i]))\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 768])\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Every token have word embedding of length 768. \n",
    "As we have 12 hidden layer so we get output after each hidden layer and can be used as a word embedding .\n",
    "But, Question is, which is the best?. Vary combinations feeding as ainput to BiLSTM for named entity recognition\n",
    "task and observeing the F1 Score. It shows sum of last 4 layers works well\n",
    "'''\n",
    "\n",
    "\n",
    "# initial embeddings can be taken from 0th layer of hidden states\n",
    "word_embed_2 = hidden_states[0]\n",
    "# sum of all hidden states\n",
    "word_embed_3 = torch.stack(hidden_states).sum(0)\n",
    "# sum of second to last layer\n",
    "word_embed_4 = torch.stack(hidden_states[2:]).sum(0)\n",
    "# sum of last four layer\n",
    "word_embed_5 = torch.stack(hidden_states[-4:]).sum(0)\n",
    "# concatenate last four layers\n",
    "word_embed_6 = torch.cat([hidden_states[i] for i in [-1,-2,-3,-4]], dim=-1)\n",
    "print(word_embed_5.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_i = 5\n",
    "layer_i = 5\n",
    "vec = hidden_states[layer_i][batch_i][token_i]\n",
    "\n",
    "# Plot the values as a histogram to show their distribution.\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.hist(vec, bins=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dda2a226026659da0aeb03523213daeeb83040b840653cf756c5e8170d297617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
